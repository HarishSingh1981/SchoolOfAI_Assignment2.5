{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarishSingh1981/SchoolOfAI_Assignment2.5/blob/main/Session2_5_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#creating own dataset to export MNIST data with a random number and label of MNIST data with sum of\n",
        "#label and random number\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self,isTraining):\n",
        "    super().__init__()\n",
        "    self.image_dataset = torchvision.datasets.MNIST(root =\"./data\",\n",
        "                                              train=isTraining,\n",
        "                                              download=True,\n",
        "                                              transform=transforms.Compose([transforms.ToTensor()]))\n",
        "    print(f'Length of Mnist dataset -- > {len(self.image_dataset)}')\n",
        "  def __len__(self):\n",
        "    return len(self.image_dataset)\n",
        "  def __getitem__(self,index):\n",
        "    #get image and label touple from data set + random number and summation of image label\n",
        "    random_no = np.random.randint(0,9)\n",
        "    sum_rand_label = random_no + self.image_dataset[index][1]\n",
        "   # print(f'label for image data is {self.image_dataset[index][1]} and random number --> {random_no}')\n",
        "    #touple2 = (random_no,sum_rand_label)\n",
        "    rand_input = torch.tensor(np.zeros(10,dtype=np.float32),device= \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    rand_input[random_no] = 1\n",
        "    rand_input.requires_grad = True\n",
        "    #print(f'Random input {random_no} --> {rand_input}')\n",
        "    #print(f'Random sum {sum_rand_label} --> {rand_sum}')\n",
        "    #print(f'{rand_arr} .....{sum_arr}')\n",
        "    #print(f'rand_array--> {rand_arr} sum_array--> {sum_arr} touple2 --> {type(touple2)}')\n",
        "    touple2 = (rand_input,sum_rand_label)\n",
        "    return self.image_dataset[index],touple2\n",
        "\n",
        "dataset = MyDataset(True)\n",
        "#print(f'type of dataset is {type(dataset)}')\n",
        "batch_size = 50\n",
        "#myData_iter = iter(dataset)\n",
        "#myData = next(myData_iter)\n",
        "#print(f'Shape of data[0] and data[1]--> {type(myData[0])} ... {type(myData[1])}')\n",
        "#print(f'{myData[0]} {myData[1]}')\n",
        "#image,label = myData[0]\n",
        "#number = myData[1]\n",
        "#print(f'label,number --> {label},{number}')\n",
        "myDataLoader = torch.utils.data.DataLoader(dataset,batch_size=batch_size,shuffle=True)\n",
        "#print(f'length of dataset --> {len(myDataSet)} and type --> {type(myDataSet)}')\n",
        "\n",
        "class MyNetwork(nn.Module):\n",
        "  def __init__(self,batch_size):\n",
        "    super().__init__()\n",
        "    #assuming we are using Mnist data set with images 28*28\n",
        "    self.conv1 = nn.Conv2d(in_channels=1,out_channels=6,kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(in_channels=6,out_channels=12,kernel_size=5)\n",
        "    self.fc1 = nn.Linear(in_features=12*4*4+10,out_features=120)\n",
        "    self.fc2 = nn.Linear(in_features=120,out_features=60)\n",
        "    self.out1 = nn.Linear(in_features=60,out_features=30)\n",
        "    self.batch_size = batch_size\n",
        "  def forward(self,x,t2):\n",
        "    #input to convolution operation in pytorch is batch_size,input_channel,height,width\n",
        "    #print(f'device for x --> {x.device} and device for t2 --> {t2.device}')\n",
        "    x = self.conv1(x) #28x28 --> 24x24\n",
        "    #relu is used as activation function for each convolutional layer\n",
        "    x = F.relu(x)\n",
        "    #reduce the size of input by 2 with max pool\n",
        "    x = F.max_pool2d(x,kernel_size=2,stride=2) #half the size to 24x24 --> 12x12\n",
        "    x = self.conv2(x) # 12x12 --> 8x8\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x,kernel_size=2,stride=2) #8x8 --> 4x4\n",
        "    #print(f'shape of sample data after relu --> {x.shape}')\n",
        "    #Flattern the input\n",
        "    x = x.reshape(self.batch_size,-1)\n",
        "    #cat operation is performed on CPU\n",
        "    t2 = t2.to(device='cpu')\n",
        "    x = torch.cat([x,t2],dim=1)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.out1(x)\n",
        "    #output one to predict image label\n",
        "    output1 = x\n",
        "    #print(f'shape of x --> {x.shape} and shape of t2 --> {t2.shape}')\n",
        "    #print(f'device for x --> {x.device} and device for t2 --> {t2.device}')\n",
        "    #return 2 ouput 10 neurons for MNIST and rest 20 for sum of random number and label for MNIST\n",
        "    return (output1[:,:10],output1[:,10:])\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#print(f'Available device -- > {device}')\n",
        "model = MyNetwork(batch_size)\n",
        "#schedule the model to run on GPU\n",
        "#print(f'gradient for conv1 {model.conv1.weight.grad}')\n",
        "#images,labels = next(iter(myDataLoader))\n",
        "#got the forward propogation and prediction\n",
        "optimizer = optim.SGD(model.parameters(),lr=0.1)\n",
        "\n",
        "model.requires_grad_(True)\n",
        "#adding epoch also now\n",
        "for epochs in range(10):\n",
        "  total_loss_mnist = 0\n",
        "  total_loss_sum = 0\n",
        "  total_correct_mnist = 0\n",
        "  total_correct_sum = 0\n",
        "  for batchs in myDataLoader:\n",
        "    #optimizer.zero_grad()\n",
        "    #print(f'type of MyDataset -- > {type(MyDataset)}')\n",
        "    #next_data = next(myData_iter)\n",
        "    images,labels_mnist = batchs[0]\n",
        "    #print(f'image device --> {images.device} and labels_mnist device --> {labels_mnist.device} ')\n",
        "    #print(f'shape of labels_mnist is {labels_mnist.shape} and shape of image is {images.shape}')\n",
        "    #print(f'type of labels_mnist is {type(labels_mnist)} and shape of image is {type(images)}')\n",
        "    #visualization of images of Mnist dataset\n",
        "    #print(f'Shape of images -- > {images.shape}')\n",
        "    #grid = torchvision.utils.make_grid(images,nrow=10)\n",
        "    #plt.figure(figsize=[15,15])\n",
        "    #reordering image dimensions\n",
        "    #plt.imshow(grid.permute(1,2,0))\n",
        "    #labels = torch.tensor(labels_mist)\n",
        "    #print(f'type of batchs and batch[0] and batch[1]--> {type(batchs)}, {type(batchs[0])}, {type(batchs[1])}')\n",
        "    #print(f'len of batchs and batch[0] and batch[1]--> {len(batchs)}, {len(batchs[0])}, {len(batchs[1])}')\n",
        "    #print(f'{batchs[0]}, {batchs[1]}')\n",
        "    random_num,label_sum = batchs[1]\n",
        "\n",
        "    #print(f'shape of random_num is {random_num.shape} and shape of label_sum is {label_sum.shape}')\n",
        "    #print(f'type of random_num is {type(random_num)} and shape of label_sum is {type(label_sum)}')\n",
        "\n",
        "    #print(f'Shape of images --> {images.shape} and labels_mist --> {labels_mist.shape}')\n",
        "    preds_mnist,preds_sum = model(images,random_num)\n",
        "    #find the error\n",
        "   # print(f'preds_mnist --> {preds_mnist.shape} and preds_sum --> {preds_sum.shape} and label_sum {label_sum.shape}')\n",
        "    #print(f'device for preds_mnist and label_sum are {preds_mnist.device} {label_sum.device}')\n",
        "    loss_mnist = F.cross_entropy(preds_mnist.to(device='cuda'),labels_mnist.to(device='cuda'))\n",
        "    loss_sum = F.cross_entropy(preds_sum.to(device='cuda'),label_sum.to(device='cuda'))\n",
        "    #It does not take 2 outputs\n",
        "    #loss = F.cross_entropy((preds_mnist,preds_sum),(labels_mist,label_sum))\n",
        "    #calculate average mean loss\n",
        "    avg_loss = loss_mnist + loss_sum\n",
        "    #calculate the gradient\n",
        "    avg_loss.backward()\n",
        "    #print(f'gradient for conv1 {model.conv1.weight.grad}')\n",
        "    #update the weights\n",
        "    optimizer.step()\n",
        "    #print(f'loss --> {loss} and values --> {pred.argmax(dim=1).eq(label).sum().item()}')\n",
        "    optimizer.zero_grad()\n",
        "    total_loss_mnist += loss_mnist\n",
        "    total_loss_sum += loss_sum\n",
        "    #print(f'Shape of pred --> {preds.shape} and labels --> {labels.shape}')\n",
        "    total_correct_mnist += preds_mnist.argmax(dim=1).eq(labels_mnist).sum().item()\n",
        "    #print(f'shape of preds_mnist {preds_mnist.shape} and shape of preds_sum {preds_sum.shape}')\n",
        "    #print(f'shape of label_sum is {label_sum.shape} and shape of lables_mist {labels_mnist.shape}')\n",
        "    preds_sum = preds_sum.to(device='cuda')\n",
        "    total_correct_sum += preds_sum.argmax(dim=1).eq(label_sum.to(device='cuda')).sum().item()\n",
        "    #print(f'{model.out2.state_dict()}')\n",
        "  print(f'epoch --> {epochs} loss_mnist --> {total_loss_mnist} and correct predictions --> {total_correct_mnist}')\n",
        "  print(f'epoch --> {epochs} loss_sum --> {total_loss_sum} and correct predictions of sum --> {total_correct_sum}')\n",
        "\n",
        "#Validate the result now\n",
        "#set the model to evaluation mode\n",
        "model.eval()\n",
        "#Load validation dataset\n",
        "batch_size = 50\n",
        "validation_dataset = MyDataset(False)\n",
        "total_correct_mnist = 0\n",
        "total_correct_sum = 0\n",
        "validation_dataloader = torch.utils.data.DataLoader(validation_dataset,batch_size=batch_size,shuffle=True)\n",
        "for data in validation_dataloader:\n",
        "    images,labels_mnist = batchs[0]\n",
        "    random_num,label_sum = batchs[1]\n",
        "    preds_mnist,preds_sum = model(images,random_num)\n",
        "    total_correct_mnist += preds_mnist.argmax(dim=1).eq(labels_mnist).sum().item()\n",
        "    preds_sum = preds_sum.to(device='cuda')\n",
        "    total_correct_sum += preds_sum.argmax(dim=1).eq(label_sum.to(device='cuda')).sum().item()\n",
        "print(f'correct predictions --> {total_correct_mnist} out of {len(validation_dataset)}')\n",
        "print(f'correct predictions of sum --> {total_correct_sum} out of {len(validation_dataset)}')\n"
      ],
      "metadata": {
        "id": "HKXSOqmxrgAI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}